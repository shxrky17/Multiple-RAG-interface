{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f3a8566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"GROQ_API_KEY\"):\n",
    "  os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter API key for Groq: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"llama3-8b-8192\", model_provider=\"groq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10739b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm just an AI, so I don't have feelings or emotions like humans do. I'm here to help you with any questions or tasks you have, though! Is there something specific you'd like to talk about or ask about?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 16, 'total_tokens': 65, 'completion_time': 0.040833333, 'prompt_time': 0.002407258, 'queue_time': 0.23710077100000002, 'total_time': 0.043240591}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'finish_reason': 'stop', 'logprobs': None}, id='run-b6e5bfb5-0043-4379-bc49-1dc4bb3e85d7-0', usage_metadata={'input_tokens': 16, 'output_tokens': 49, 'total_tokens': 65})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbfbf26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Here's one:\\n\\nWhy couldn't the bicycle stand up by itself?\\n\\n(Wait for it...)\\n\\nBecause it was two-tired!\\n\\nHope that made you smile!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 43, 'total_tokens': 76, 'completion_time': 0.0275, 'prompt_time': 0.005946345, 'queue_time': 0.23945597400000002, 'total_time': 0.033446345}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_a97cfe35ae', 'finish_reason': 'stop', 'logprobs': None}, id='run-68054812-f1af-4891-9395-609eae47436b-0', usage_metadata={'input_tokens': 43, 'output_tokens': 33, 'total_tokens': 76})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"I'm doing well, thank you for asking.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Can you tell me a joke?\",\n",
    "    }\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3982c32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool, InjectedToolArg\n",
    "\n",
    "@tool\n",
    "def user_specific_tool(input_data: str, user_id: InjectedToolArg) -> str:\n",
    "    \"\"\"Tool that processes input data.\"\"\"\n",
    "    return f\"User {user_id} processed {input_data}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3ae453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "\n",
    "class add(TypedDict):\n",
    "    \"\"\"Add two integers.\"\"\"\n",
    "\n",
    "    # Annotations must have the type and can optionally include a default value and description (in that order).\n",
    "    a: Annotated[int, ..., \"First integer\"]\n",
    "    b: Annotated[int, ..., \"Second integer\"]\n",
    "\n",
    "\n",
    "class multiply(TypedDict):\n",
    "    \"\"\"Multiply two integers.\"\"\"\n",
    "\n",
    "    a: Annotated[int, ..., \"First integer\"]\n",
    "    b: Annotated[int, ..., \"Second integer\"]\n",
    "\n",
    "\n",
    "tools = [add, multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3fdd279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_we5a', 'function': {'arguments': '{\"a\":3,\"b\":12}', 'name': 'multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 1064, 'total_tokens': 1136, 'completion_time': 0.06, 'prompt_time': 0.173003763, 'queue_time': 0.628693273, 'total_time': 0.233003763}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_dadc9d6142', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-1e4fc233-577e-45fa-be30-57566354fb7c-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_we5a', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1064, 'output_tokens': 72, 'total_tokens': 1136})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools = model.bind_tools(tools)\n",
    "\n",
    "query = \"What is 3 * 12?\"\n",
    "\n",
    "llm_with_tools.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf511484",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yash",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
